# news_utils.py
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote, unquote

def get_news(topic="‡∏Ç‡πà‡∏≤‡∏ß"):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î 3 ‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å Google News (‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢/‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á)
    """
    try:
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ User-Agent ‡πÅ‡∏•‡∏∞ URL
        headers = {
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/125.0.0.0 Safari/537.36"
            )
        }
        url = f"https://www.google.com/search?q={quote(topic)}&tbm=nws&hl=th"
        resp = requests.get(url, headers=headers, timeout=8)
        if not resp.ok or not resp.text:
            return "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google News ‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ"

        soup = BeautifulSoup(resp.text, "lxml")
        results = []
        for div in soup.select("div.Gx5Zad.fP1Qef.xpd.EtOod.pkphOe"):
            # ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡πà‡∏≤‡∏ß Google ‡∏à‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô class ‡πÑ‡∏î‡πâ ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ fallback
            title_tag = div.select_one("div.BNeawe.vvjwJb.AP7Wnd")
            title = title_tag.text.strip() if title_tag else None

            link_tag = div.select_one("a")
            link = link_tag["href"] if link_tag and "href" in link_tag.attrs else ""
            # Google news: "/url?q=https://xxx"
            if link.startswith("/url?q="):
                link = link.split("/url?q=")[1].split("&")[0]
                link = unquote(link)

            summary_tag = div.select_one("div.BNeawe.s3v9rd.AP7Wnd")
            summary = summary_tag.text.strip() if summary_tag else ""

            if title and link:
                results.append(f"‚Ä¢ {title}\n{link}\n{summary}")
            if len(results) >= 3:
                break

        # fallback: selector ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤
        if not results:
            for n in soup.select("div.g"):
                title = n.select_one("h3")
                link = n.select_one("a")
                snippet = n.select_one("div.BNeawe.s3v9rd.AP7Wnd")
                if title and link:
                    url_news = link['href']
                    if url_news.startswith("/url?q="):
                        url_news = url_news.split("/url?q=")[1].split("&")[0]
                        url_news = unquote(url_news)
                    summary = snippet.text.strip() if snippet else ""
                    results.append(f"‚Ä¢ {title.text.strip()}\n{url_news}\n{summary}")
                if len(results) >= 3: break

        if results:
            return "üì∞ ‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:\n" + "\n\n".join(results)
        return "‚ùå ‡∏Ç‡∏≠‡πÇ‡∏ó‡∏© ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å Google News ‡πÉ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ"
    except Exception as e:
        return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πà‡∏≤‡∏ß: {e}"
