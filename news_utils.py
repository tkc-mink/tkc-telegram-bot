import requests
from bs4 import BeautifulSoup
from urllib.parse import quote

def get_news(topic="‡∏Ç‡πà‡∏≤‡∏ß"):
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Google News ‡∏ï‡∏≤‡∏° keyword/topic ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏
    ‡πÅ‡∏™‡∏î‡∏á headline + link + ‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡πà‡∏≠ 2-3 ‡∏Ç‡πà‡∏≤‡∏ß (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)
    """
    try:
        url = f"https://www.google.com/search?q={quote(topic)}&tbm=nws&hl=th"
        headers = {
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/125.0.0.0 Safari/537.36"
            )
        }
        resp = requests.get(url, headers=headers, timeout=7)
        soup = BeautifulSoup(resp.text, "lxml")
        items = []

        # Google News DOM ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ö‡πà‡∏≠‡∏¢, ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö fallback
        for n in soup.select("div.g"):
            title = n.select_one("h3")
            link = n.select_one("a")
            snippet = n.select_one("div.BNeawe.s3v9rd.AP7Wnd")
            if title and link:
                url_news = link['href']
                if url_news.startswith("/url?q="):
                    url_news = url_news.split("/url?q=")[1].split("&")[0]
                summary = snippet.text.strip() if snippet else ""
                items.append(f"‚Ä¢ {title.text.strip()}\n{url_news}\n{summary}")
            if len(items) >= 3:
                break

        # Fallback: ‡∏ñ‡πâ‡∏≤ Google ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Å‡∏≤‡∏£ block
        if not items:
            # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
            url_en = f"https://www.google.com/search?q={quote(topic)}&tbm=nws&hl=en"
            resp_en = requests.get(url_en, headers=headers, timeout=7)
            soup_en = BeautifulSoup(resp_en.text, "lxml")
            for n in soup_en.select("div.g"):
                title = n.select_one("h3")
                link = n.select_one("a")
                snippet = n.select_one("div.BNeawe.s3v9rd.AP7Wnd")
                if title and link:
                    url_news = link['href']
                    if url_news.startswith("/url?q="):
                        url_news = url_news.split("/url?q=")[1].split("&")[0]
                    summary = snippet.text.strip() if snippet else ""
                    items.append(f"‚Ä¢ {title.text.strip()}\n{url_news}\n{summary}")
                if len(items) >= 3:
                    break

        if items:
            return "üì∞ ‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:\n" + "\n\n".join(items)
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å Google News ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ"

    except Exception as e:
        print(f"[news_utils] error: {e}")
        return f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πà‡∏≤‡∏ß: {str(e)}"
