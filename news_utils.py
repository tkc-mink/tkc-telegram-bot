import requests
from bs4 import BeautifulSoup
from urllib.parse import quote

def get_news(topic="‡∏Ç‡πà‡∏≤‡∏ß"):
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Google News (‡πÑ‡∏ó‡∏¢/‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©) ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 3 ‡∏Ç‡πà‡∏≤‡∏ß
    :param topic: ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô "‡∏Ç‡πà‡∏≤‡∏ß", "‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à", "technology")
    :return: ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏ß‡∏°‡∏Ç‡πà‡∏≤‡∏ß 3 ‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    """
    try:
        url = f"https://www.google.com/search?q={quote(topic)}&tbm=nws&hl=th"
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(url, headers=headers, timeout=7)
        soup = BeautifulSoup(resp.text, "lxml")
        items = []
        for n in soup.select("div.g"):
            title = n.select_one("h3")
            link = n.select_one("a")
            snippet = n.select_one("div.BNeawe.s3v9rd.AP7Wnd")
            if title and link:
                url_news = link['href']
                # Google sometimes uses "/url?q=" prefix
                if url_news.startswith("/url?q="):
                    url_news = url_news.split("/url?q=")[1].split("&")[0]
                summary = snippet.text.strip() if snippet else ""
                items.append(f"‚Ä¢ {title.text.strip()}\n{url_news}\n{summary}")
            if len(items) >= 3:
                break
        if items:
            return "üì∞ ‡∏Ç‡πà‡∏≤‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:\n" + "\n\n".join(items)
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å Google News ‡∏Ñ‡∏£‡∏±‡∏ö"
    except Exception as e:
        print(f"[news_utils] Error: {e}")
        return f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πà‡∏≤‡∏ß: {str(e)}"
