# handlers/doc.py
# -*- coding: utf-8 -*-
import os
from typing import List, Tuple

from utils.message_utils import send_message
from utils.history_utils import log_message
from utils.doc_extract_utils import (
    extract_text_pdf,
    extract_text_docx,
    extract_text_xlsx,
    extract_text_pptx,
)
from utils.telegram_file_utils import download_telegram_file
from utils.telegram_api import send_chat_action  # ‡πÅ‡∏à‡πâ‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÉ‡∏ô Telegram
from function_calling import summarize_text_with_gpt  # ‡πÉ‡∏ä‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏° (‡∏°‡∏µ No-Echo ‡πÅ‡∏•‡πâ‡∏ß)

# ---------------- Env / Config ----------------
# ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡πâ‡∏≠‡∏ô‡∏™‡∏£‡∏∏‡∏õ (‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£) ‚Äî ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 2‚Äì3k tokens ‡∏ï‡πà‡∏≠‡∏Å‡πâ‡∏≠‡∏ô
_CHUNK_CHARS = int(os.getenv("DOC_SUMMARY_CHUNK_CHARS", "6000"))
# ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡πâ‡∏≠‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡∏ß‡∏ï‡∏≤
_MAX_CHUNKS  = int(os.getenv("DOC_SUMMARY_MAX_CHUNKS", "8"))
# ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå (MB)
_MAX_FILE_MB = int(os.getenv("DOC_MAX_FILE_MB", "25"))

_SUPPORTED_EXT = {".pdf", ".docx", ".xlsx", ".pptx", ".txt"}


# ---------------- Helpers ----------------
def _human_mb(n_bytes: int) -> float:
    try:
        return round(n_bytes / (1024 * 1024), 2)
    except Exception:
        return 0.0

def _split_text_smart(text: str, size: int) -> List[str]:
    """
    ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡πâ‡∏≠‡∏ô ‡πÜ ‡πÇ‡∏î‡∏¢‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° '‡πÑ‡∏°‡πà‡∏ï‡∏±‡∏î‡∏Å‡∏•‡∏≤‡∏á‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤/‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ'
    ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô:
      1) ‡∏ï‡∏±‡∏î‡∏î‡πâ‡∏ß‡∏¢ "\n\n" (‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤)
      2) ‡∏™‡∏∞‡∏™‡∏°‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏ô‡πÉ‡∏Å‡∏•‡πâ size ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡πâ‡∏≠‡∏ô‡πÉ‡∏´‡∏°‡πà
      3) ‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô size ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å fallback ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡πÅ‡∏ö‡∏ö‡∏ï‡∏£‡∏á ‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ï‡∏Å‡∏´‡∏•‡πà‡∏ô
    """
    text = (text or "").strip()
    if not text:
        return []

    paras = text.split("\n\n")
    chunks: List[str] = []
    buf: List[str] = []
    cur_len = 0

    for p in paras:
        p = p.strip()
        if not p:
            continue
        if len(p) > size:
            # ‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡∏°‡∏´‡∏∂‡∏°‡∏≤: ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ï‡∏±‡∏î‡∏ï‡∏£‡∏á ‡πÜ
            if buf:
                chunks.append("\n\n".join(buf).strip())
                buf, cur_len = [], 0
            for i in range(0, len(p), size):
                chunks.append(p[i:i+size])
            continue

        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏ï‡∏¥‡∏°‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô size -> ‡∏õ‡∏¥‡∏î‡∏Å‡πâ‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏Å‡πà‡∏≠‡∏ô
        if cur_len + len(p) + (2 if buf else 0) > size:
            if buf:
                chunks.append("\n\n".join(buf).strip())
            buf, cur_len = [p], len(p)
        else:
            buf.append(p)
            cur_len += len(p) + (2 if buf else 0)

    if buf:
        chunks.append("\n\n".join(buf).strip())

    return chunks


def _hierarchical_summarize(full_text: str) -> str:
    """
    ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: ‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡πà‡∏≠‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≠‡∏ô ‡πÜ ‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏ß‡∏°‡∏™‡∏£‡∏∏‡∏õ‡∏≠‡∏µ‡∏Å‡∏ä‡∏±‡πâ‡∏ô
    ‡∏ñ‡πâ‡∏≤‡∏™‡∏±‡πâ‡∏ô: ‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    """
    text = (full_text or "").strip()
    if not text:
        return "‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"

    if len(text) <= _CHUNK_CHARS:
        return summarize_text_with_gpt(text)

    chunks = _split_text_smart(text, _CHUNK_CHARS)
    if not chunks:
        return "‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ"

    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡πâ‡∏≠‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    chunks = chunks[:_MAX_CHUNKS]

    partials: List[str] = []
    total = len(chunks)
    for idx, ck in enumerate(chunks, 1):
        # ‡πÉ‡∏™‡πà‡∏´‡∏±‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£
        partial = summarize_text_with_gpt(f"[‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà {idx}/{total}]\n{ck}")
        partials.append(partial)

    merged = "\n\n".join(f"- {p}" for p in partials if p)
    final = summarize_text_with_gpt(
        "‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏ß‡∏°‡πÅ‡∏ö‡∏ö bullet ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£:\n" + merged
    )
    return final


def _validate_document_meta(doc: dict) -> Tuple[bool, str]:
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏ô‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡∏≤‡∏° metadata ‡∏ó‡∏µ‡πà Telegram ‡∏™‡πà‡∏á‡∏°‡∏≤
    file_name = doc.get("file_name", "document")
    ext = os.path.splitext(file_name)[1].lower()
    if ext not in _SUPPORTED_EXT:
        return False, "‚ùå ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ PDF, Word (docx), Excel (xlsx), PowerPoint (pptx), ‡πÅ‡∏•‡∏∞ TXT"

    # ‡∏ö‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á Telegram ‡∏à‡∏∞‡πÉ‡∏´‡πâ file_size ‡∏°‡∏≤‡∏î‡πâ‡∏ß‡∏¢ (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏∞‡∏Ç‡πâ‡∏≤‡∏°)
    size = doc.get("file_size")
    if isinstance(size, int) and size > 0:
        mb = _human_mb(size)
        if mb > _MAX_FILE_MB:
            return False, f"‚ùå ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ({mb} MB) ‚Äî ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì {_MAX_FILE_MB} MB"

    return True, ""


# ---------------- Entry ----------------
def handle_doc(chat_id, msg):
    """
    ‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Telegram ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏£‡∏∏‡∏õ (PDF, DOCX, XLSX, PPTX, TXT)
    """
    doc = msg.get("document") or {}
    if not doc:
        send_message(chat_id, "‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏ö‡∏°‡∏≤")
        return

    ok, why = _validate_document_meta(doc)
    if not ok:
        send_message(chat_id, why)
        return

    file_name = doc.get("file_name", "document")
    file_id = doc.get("file_id")
    user_id = str(chat_id)

    # ‡πÅ‡∏à‡πâ‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    try:
        send_chat_action(chat_id, "typing")  # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    except Exception:
        pass
    send_message(chat_id, f"üì• ‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå **{file_name}** ‡πÅ‡∏•‡πâ‡∏ß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‚Ä¶")

    local_path = None
    try:
        # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Telegram
        local_path = download_telegram_file(file_id, file_name)
        if not local_path or not os.path.exists(local_path):
            send_message(chat_id, "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ ‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡∏£‡∏±‡∏ö")
            return

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î (‡πÄ‡∏ú‡∏∑‡πà‡∏≠ metadata ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á)
        real_mb = _human_mb(os.path.getsize(local_path))
        if real_mb > _MAX_FILE_MB:
            send_message(chat_id, f"‚ùå ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ({real_mb} MB) ‚Äî ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì {_MAX_FILE_MB} MB")
            return

        ext = os.path.splitext(file_name)[1].lower()

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡∏ä‡∏ô‡∏¥‡∏î
        if ext == ".pdf":
            text = extract_text_pdf(local_path)
        elif ext == ".docx":
            text = extract_text_docx(local_path)
        elif ext == ".xlsx":
            text = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Excel:\n" + extract_text_xlsx(local_path)
        elif ext == ".pptx":
            text = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô PowerPoint:\n" + extract_text_pptx(local_path)
        elif ext == ".txt":
            with open(local_path, encoding="utf-8", errors="ignore") as f:
                text = f.read()
        else:
            send_message(chat_id, "‚ùå ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞ PDF, Word (docx), Excel (xlsx), PowerPoint (pptx), ‡πÅ‡∏•‡∏∞ TXT")
            return

        text = (text or "").strip()
        if not text:
            send_message(chat_id, "‚ö†Ô∏è ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏£‡∏±‡∏ö")
            return

        # ‡∏™‡∏£‡∏∏‡∏õ (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏¢‡∏≤‡∏ß‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≠‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏â‡∏•‡∏≤‡∏î)
        summary = _hierarchical_summarize(text)

        send_message(chat_id, f"üìÑ ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏ü‡∏•‡πå **{file_name}**\n\n{summary}")
        log_message(user_id, f"‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏ü‡∏•‡πå {file_name}", summary)

    except Exception as e:
        send_message(chat_id, f"‚ùå ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
    finally:
        # ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡πÄ‡∏™‡∏°‡∏≠
        try:
            if local_path and os.path.exists(local_path):
                os.remove(local_path)
        except Exception:
            pass
